{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Median combination of GMOS-N and GMOS-S flatfield files\n",
    "\n",
    "Creates median-combined flatfield images (as individual extension files) for processing GMOS-N and GMOS-S science data after initial reduction (overscan correction, trimming, and bias subtraction) and screening to ensure mean counts for all files lie within a desired range.\n",
    "\n",
    "## Before running notebook:\n",
    "\n",
    "- Install <tt>fpack</tt> and <tt>funpack</tt> if not already installed (https://heasarc.gsfc.nasa.gov/fitsio/fpack/); change paths to local installation location in functions <tt>compress_file_fpack</tt> and <tt>decompress_file_fpack</tt> in this notebook<br><br>\n",
    "\n",
    "- Run <tt>notebook_GMOS_a01_12amp_process_raw_twilight_flats.ipynb</tt> to perform initial processing of bias and flatfield images for the given night<br><br>\n",
    "\n",
    "- Create folder named \"<tt>exclude</tt>\" in <tt>procfits_twiskyflat</tt> folder in data directory for the given night produced by the previous notebook.  The existence of this folder is used by this notebook to determine whether a given data folder is ready for further processing<br><br>\n",
    "\n",
    "- View image statistics file (\"<tt>nYYYYMMDD.stats</tt>\") in <tt>procfits_twiskyflat</tt> folder in data directory for the given night, and determine which twilight sky frames, if any, should be excluded from construction of a median flatfield (i.e., has mean counts that are too low or too high, e.g., < 10000 or >50000); move these frames (make sure to move all three chips associated with each frame) to <tt>exclude</tt> folder to remove from further processing<br><br>\n",
    "\n",
    "- Run <tt>process_flatfield_directory(base_path,date_id,filter_id,observatory)</tt> where base_path is the directory containing the <tt>procfits_twiskyflat</tt> sub-directory, <tt>date_id</tt> is the date of observations in YYYYMMDD format, <tt>filter_id</tt> is the one-letter name of the filter used for the flatfield images (e.g., <tt>g</tt>, <tt>r</tt>, <tt>i</tt>, or <tt>z</tt>), and observatory is either \"<tt>GeminiN</tt>\" or \"<tt>GeminiS</tt>\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os, sys\n",
    "from astropy.io import fits\n",
    "from astropy.io.fits import getheader\n",
    "from astropy.modeling import models\n",
    "from astropy import nddata\n",
    "from astropy import units as u\n",
    "import ccdproc as cp\n",
    "from ccdproc import CCDData\n",
    "import numpy as np\n",
    "import glob, subprocess\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directory(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    else:\n",
    "        print('Directory {:s} already exists.'.format(path))\n",
    "    return None\n",
    "\n",
    "def compress_file_fpack(filename):\n",
    "    process = subprocess.call(['/Users/hhsieh/Astro/tools/cfitsio/fpack',filename])\n",
    "    os.remove(filename)\n",
    "    return None\n",
    "\n",
    "def decompress_file_fpack(filename):\n",
    "    process = subprocess.call(['/Users/hhsieh/Astro/tools/cfitsio/funpack',filename])\n",
    "    os.remove(filename)\n",
    "    return None\n",
    "\n",
    "def compress_directory_fpack(file_path):\n",
    "    print('>>> Starting fpack compression of FITS files in {:s}...'.format(file_path))\n",
    "    os.chdir(file_path)\n",
    "    for fits_file in glob.glob('*.fits'):\n",
    "        compress_file_fpack(fits_file)\n",
    "    print('>>> fpack compression of FITS files complete.')\n",
    "    return None\n",
    "    \n",
    "def decompress_directory_fpack(file_path):\n",
    "    print('>>> Starting decompression of fz files in {:s}...'.format(file_path))\n",
    "    os.chdir(file_path)\n",
    "    for fz_file in glob.glob('*.fz'):\n",
    "        decompress_file_fpack(fz_file)\n",
    "    print('>>> Decompression of fz files complete.')\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date_id():\n",
    "    # obtain YYYYMMDD date from filename of GMOS FITS files being processed\n",
    "    for raw_mef_file in glob.glob('*.fits'):\n",
    "        fits_date = raw_mef_file[1:9]\n",
    "    return fits_date\n",
    "\n",
    "def flatfield_median_combine(flatfield_name,reduction_log):\n",
    "    print('{:s} - Starting median combination of flatfield frames...'.format(datetime.datetime.today().strftime('%Y-%m-%d %H:%M:%S')))\n",
    "    reduction_log.write('{:s} - Starting median combination of flatfield frames...\\n'.format(datetime.datetime.today().strftime('%Y-%m-%d %H:%M:%S')))\n",
    "\n",
    "    flatfield_list = []\n",
    "    output_flat_filename = flatfield_name + '.chip1.fits'\n",
    "    for fits_file in glob.glob('*.chip1.otz.fits'):\n",
    "        with fits.open(fits_file) as hdulist:\n",
    "            fits_hdr,fits_data = hdulist[0].header,hdulist[0].data\n",
    "            fits_mean   = np.mean(fits_data)\n",
    "            fits_data_n = fits_data / fits_mean\n",
    "            #file_prefix = fits_file[0:19]\n",
    "            #fits_file_n = file_prefix + '_n.otz.fits'\n",
    "            fits_file_n = fits_file[0:19] + '_n.otz.fits'\n",
    "            fits.writeto(fits_file_n,fits_data_n,fits_hdr)\n",
    "        fits_data = CCDData.read(fits_file_n)\n",
    "        flatfield_list.append(fits_data)\n",
    "        os.remove(fits_file_n)\n",
    "    master_flat = cp.combine(flatfield_list,method='median')\n",
    "    master_flat.write(output_flat_filename)\n",
    "    print('>>> Median combination of flatfield frames for Chip 1 complete.')\n",
    "    reduction_log.write('>>> Median combination of flatfield frames for Chip 1 complete.\\n')\n",
    "\n",
    "    flatfield_list = []\n",
    "    output_flat_filename = flatfield_name + '.chip2.fits'\n",
    "    for fits_file in glob.glob('*.chip2.otz.fits'):\n",
    "        with fits.open(fits_file) as hdulist:\n",
    "            fits_hdr,fits_data = hdulist[0].header,hdulist[0].data\n",
    "            fits_mean   = np.mean(fits_data[251:1012,1:2042])\n",
    "            fits_data_n = fits_data / fits_mean\n",
    "            fits_file_n = fits_file[0:19] + '_n.otz.fits'\n",
    "            fits.writeto(fits_file_n,fits_data_n,fits_hdr)\n",
    "        fits_data = CCDData.read(fits_file_n)\n",
    "        flatfield_list.append(fits_data)\n",
    "        os.remove(fits_file_n)\n",
    "    master_flat = cp.combine(flatfield_list,method='median')\n",
    "    master_flat.write(output_flat_filename)\n",
    "    print('>>> Median combination of flatfield frames for Chip 2 complete.')\n",
    "    reduction_log.write('>>> Median combination of flatfield frames for Chip 2 complete.\\n')\n",
    "\n",
    "    flatfield_list = []\n",
    "    output_flat_filename = flatfield_name + '.chip3.fits'\n",
    "    for fits_file in glob.glob('*.chip3.otz.fits'):\n",
    "        with fits.open(fits_file) as hdulist:\n",
    "            fits_hdr,fits_data = hdulist[0].header,hdulist[0].data\n",
    "            fits_mean   = np.mean(fits_data)\n",
    "            fits_data_n = fits_data / fits_mean\n",
    "            fits_file_n = fits_file[0:19] + '_n.otz.fits'\n",
    "            fits.writeto(fits_file_n,fits_data_n,fits_hdr)\n",
    "        fits_data = CCDData.read(fits_file_n)\n",
    "        flatfield_list.append(fits_data)\n",
    "        os.remove(fits_file_n)\n",
    "    master_flat = cp.combine(flatfield_list,method='median')\n",
    "    master_flat.write(output_flat_filename)\n",
    "    print('>>> Median combination of flatfield frames for Chip 3 complete.')\n",
    "    reduction_log.write('>>> Median combination of flatfield frames for Chip 3 complete.\\n')\n",
    "\n",
    "    print('{:s} - Median combination of flatfield frames complete.'.format(datetime.datetime.today().strftime('%Y-%m-%d %H:%M:%S')))\n",
    "    reduction_log.write('{:s} - Median combination of flatfield frames complete.\\n'.format(datetime.datetime.today().strftime('%Y-%m-%d %H:%M:%S')))\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_flatfield_directory(data_path,date_id,filter_id,observatory):\n",
    "    instrname = 'not recognized'\n",
    "    if observatory == 'GeminiN': instrname = 'gmosn'\n",
    "    if observatory == 'GeminiS': instrname = 'gmoss'\n",
    "\n",
    "    os.chdir(data_path)\n",
    "    path_rawfits  = data_path + 'rawfits_twiskyflat/'\n",
    "    path_rawbias  = data_path + 'rawfits_bias/'\n",
    "    path_procfits = data_path + 'procfits_twiskyflat/'\n",
    "    path_exclfits = data_path + 'procfits_twiskyflat/exclude/'\n",
    "    \n",
    "    flatfield_name = 'n' + date_id + '.' + instrname + '.twiskyflat.' + filter_id\n",
    "    flatfits_file_chip2 = path_procfits + flatfield_name + '.chip2.fits.fz'\n",
    "    reduction_logfile = data_path + 'log_reduction_' + date_id + '_' + instrname + '.txt'\n",
    "    \n",
    "    if os.path.exists(flatfits_file_chip2):\n",
    "        print('{:s} - Median flatfields for {:s} already generated.'.format(datetime.datetime.today().strftime('%Y-%m-%d %H:%M:%S'),data_path))\n",
    "    elif not os.path.exists(path_procfits):\n",
    "        print('{:s} - Flatfield files in {:s} not yet processed.'.format(datetime.datetime.today().strftime('%Y-%m-%d %H:%M:%S'),data_path))\n",
    "    elif not os.path.exists(path_exclfits):\n",
    "        print('{:s} - Flatfield files in {:s} not yet screened.'.format(datetime.datetime.today().strftime('%Y-%m-%d %H:%M:%S'),data_path))\n",
    "    elif instrname == 'not recognized':\n",
    "        print('{:s} - Instrument for {:s} not recognized.'.format(datetime.datetime.today().strftime('%Y-%m-%d %H:%M:%S'),data_path))\n",
    "    else:\n",
    "        with open(reduction_logfile,'w') as reduction_log:\n",
    "            print('{:s} - Starting median combination of flatfield files in {:s}...'.format(datetime.datetime.today().strftime('%Y-%m-%d %H:%M:%S'),data_path))\n",
    "            reduction_log.write('{:s} - Starting median combination of flatfield files in {:s}...\\n'.format(datetime.datetime.today().strftime('%Y-%m-%d %H:%M:%S'),data_path))\n",
    "            os.chdir(path_procfits)\n",
    "            decompress_directory_fpack(path_procfits)                \n",
    "            flatfield_median_combine(flatfield_name,reduction_log)\n",
    "            compress_directory_fpack(path_procfits)     \n",
    "            print('{:s} - Processing flatfield files in {:s} complete.'.format(datetime.datetime.today().strftime('%Y-%m-%d %H:%M:%S'),data_path))\n",
    "            reduction_log.write('{:s} - Processing flatfield files in {:s} complete.\\n'.format(datetime.datetime.today().strftime('%Y-%m-%d %H:%M:%S'),data_path))\n",
    "        \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date_id: date of observations in YYYYMMDD format\n",
    "# filter_id: single letter filter name (e.g., g, r, i, or z)\n",
    "# observatory: 'GeminiN' or 'GeminiS'\n",
    "\n",
    "process_flatfield_directory('/volumes/Fantom12a/BackupData/gemini/data_calib/GMOS-S_TwilightFlats_20150101_present/GMOS-S_Twilight_Flats_r/test_obs/','20150115','r','GeminiS')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
